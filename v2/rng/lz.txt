while input is not empty do
    prefix := longest prefix of input that begins in window
    
    if prefix exists then
        i := distance to start of prefix
        l := length of prefix
        c := char following prefix in input
    else
        i := 0
        l := 0
        c := first char of input
    end if
    
    output (i, l, c)
    
    s := pop l + 1 chars from front of input
    discard l + 1 chars from front of window
    append s to back of window
repeat

LZ1 looks for repeated sequences of data, and records references to these duplicated chunks by
storing pointers alongside the original information. These pointers are then used to rebuild
the data back to its original structure. It works as follows: bytes are read in a sequence
from first to last, the location of the byte currently being inspected is known as the
'coding point'. Each byte at the coding point is compared to information preceding it, in
a buffer known as a 'window', this window would not be expected to match the whole size of
the data, but it may extend to more than a few thousand bytes. If one, or many bytes within
this window match the sequence currently located at the coding point, then a pointer is
saved to the compressed data. This pointer consists of an offset from the current coding
point to the repeated data, and how many bytes have been matched. This value is
subsequently described as the pointer's 'length'. When the pointer is recorded, the byte
immediately after the matched sequence at the coding point is also stored. If no match was
found within the window, which would always happen when the first element is read from a
file, then a null pointer is saved along with the byte at the coding point is saved
with it. So whether we find a match in our window or not, we always save a pointer
alongside a single byte as we work our way through the data.

So take the following example, a string of 'A's, followed by a 'B', and finally a 'C':
AAAAAAAABC
The first 'A' is inspected, and the window contains no data at this point, so a
null pointer is recorded alongside the byte at the coding point, i.e. the letter A.
The coding point then moves to the next byte, the second 'A'. The algorithm has
seen this before, namely in the previous byte, then it looks at how many bytes that
follows also match if we were to advance the coding point whilst still referring back
to the offset, which at the moment has the value of one. This is where the algorithm
can be quite clever and match beyond the current coding point; currently the pointer
is located at the first byte, and the coding point at the second, both are
incremented whilst both the bytes located at each match. In this case, the
total amount of bytes that are equivalent is seven, this will be until the 'B'
is reached. If at this point we had already read more data, and therefore the
window would be larger, then we would perform the same matching operation further
down the data for the entire size of the window. Since this is our only, and therefore
longest match, a pointer with the offset of one and a length of seven is written to the
compressed data, as is next byte at the coding point beyond the pointer length, the
letter B. And now the coding point moves past the 'B', and is inspected the final
byte. It hasn't seen a 'C' before in the window, so a null-pointer is saved along
with the letter C. It's important to avoid pushing the coding point past the length
of the data when storing the final pointer and byte. To illustrate this scenario,
consider this example: if our piece of data was composed only of eight 'A's,
without the 'B', or 'C', then the initial 'A' would be recorded with a null-pointer,
as previously noted, then a pointer to the first 'A' with a pointer length of six,
with the final 'A' alongside it. The reason we would give the pointer a length of
six and not seven is because we would still need to record the final byte along
with the pointer, and matching seven characters in our pointer would force the
coding point to go beyond the length of the data because an additional byte is
expected with the final pointer.

Decompressing is an extremely simple task, the coding point and window are still held
in memory whilst the data is being decoded. When a pointer offset is encountered, 
the data at the pointer offset is copied to the current coding point for however many 
times have been recorded by the pointer length, after this, the byte held with the 
pointer is then inserted at the coding point. So for our first example, the null-pointer 
is found and ignored, and then the first byte, the 'A', is read and inserted at the 
coding point. The second pointer is read, and we can see that the offset refers back 
to the previous character, so we copy everything we've already inserted at our 
previous coding point for the next seven iterations. This will give us seven 
'A's. Alongside the pointer, the next character is given, 'B', so we add that at 
our coding point, and advance the coding point again. Finally, a null-pointer is 
discovered along with the final byte, a 'C', so we ignore the pointer and add the byte 
at the coding point. After this, our original data structure has successfully been rebuilt.

Adding pointers to the compressed data incurs a cost as well as a benefit. If the pointer 
is too large when stored in the compressed data, then it would become less useful. For 
this reason the size of the window and the length of bytes are also limited. For the 
code examples that follow, I've chosen to store the pointers a 16-bit byte, twelve bits 
specify a pointer offset, and four for the length. This results in a window of 4096 
bytes, and a maximum pointer length of fifteen bytes. After experimenting with various 
combinations of size and length, a 16-bit pointer with these dimensions appears to be 
a beneficial trade-off. For most text files it's unlikely that a sequence longer than 
fifteen bytes would be repeated - although this would be more suitable for machine 
readable files with long portions of repeated data. A window of 4096 bytes also gives a 
good chance to find repeated data, anything smaller than this appears to negatively impact 
the size of the compressed data. Having a window that is excessively large also increases 
the time it takes to compress the data, as ultimately more data is compared. 
There are also memory constraints to consider too if the compression and decompression 
routines only store the window when performing its task.

